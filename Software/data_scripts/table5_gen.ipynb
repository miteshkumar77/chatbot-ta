{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import hashlib\n",
    "from urllib.parse import urljoin\n",
    "import json\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "  \"What are vendors of microcontrollers?\",\n",
    "  \"Where can I find microcontrollers or CPUs?\",\n",
    "  \"What is SVN?\",\n",
    "  \"What is the final deliverable in capstone?\",\n",
    "  \"Where are the templates for design reports located?\",\n",
    "  \"How do I order parts?\",\n",
    "  \"How do I resolve an issue?\",\n",
    "  \"How do I upload to the repository?\",\n",
    "  \"What are the learning goals of capstone?\"\n",
    "]\n",
    "server_url = \"http://45.77.102.63:8000\"\n",
    "ask_endpoint = urljoin(server_url, 'ask')\n",
    "\n",
    "try:\n",
    "  with open('request_memoizations.json', 'r') as question_context_f:\n",
    "    question_context_data = json.load(question_context_f)\n",
    "except FileNotFoundError as _:\n",
    "  question_context_data = dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_qc_request(question):\n",
    "  if question not in question_context_data:\n",
    "    question_context_data[question] = requests.post(url=ask_endpoint, data=json.dumps({'question': question})).json()\n",
    "    with open('request_memoizations.json', 'w') as question_context_f:\n",
    "      json.dump(question_context_data, question_context_f)\n",
    "  \n",
    "  return [{'question': question, 'context': ''.join(e['surrounding_context_text']),\n",
    "  'answer': e['answer_text'], 'answer_start': len(e['surrounding_context_text'][0])} for e in question_context_data[question]['answers']]\n",
    "\n",
    "\n",
    "\n",
    "def get_context_and_answers(question_list):\n",
    "  return list(itertools.chain.from_iterable(map(lambda q : make_qc_request(q), question_list)))\n",
    "\n",
    "def save_as_dataset(question_context_list):\n",
    "  try:\n",
    "    with open('dataset.json', 'r') as dsfp:\n",
    "      ds = json.load(dsfp)\n",
    "  except FileNotFoundError as _:\n",
    "    ds = {\"version\": \"0.1.0\", \"data\": []}\n",
    "\n",
    "  for el in question_context_list:\n",
    "    question = el['question']\n",
    "    context = el['context']\n",
    "    text = [el['answer']]\n",
    "    answer_start = [el['answer_start']]\n",
    "    title = 'capstone_validation_set'\n",
    "    answers = {'text': text, 'answer_start': answer_start}\n",
    "    id = hashlib.sha384((question + context).encode()).hexdigest()\n",
    "    add = True \n",
    "    for o in ds['data']:\n",
    "      if o['id'] == id:\n",
    "        add = False\n",
    "        if 'answer_start' not in o['answers']:\n",
    "          o['answers']['answer_start'] = list(map(lambda a : o['context'].find(a), o['answers']['text']))\n",
    "\n",
    "    if add:\n",
    "      ds[\"data\"][\"validation\"].append({'id': id, 'title': title, 'context': context, 'question': question, 'answers': answers})\n",
    "    ds[\"data\"][\"validation\"].sort(key=lambda o : o['question'] + o['context'])\n",
    "  with open('dataset.json', 'w') as dsfp:\n",
    "    json.dump(ds, dsfp)\n",
    "\n",
    "def update_answer_start():\n",
    "  try:\n",
    "    with open('dataset.json', 'r') as dsfp:\n",
    "      ds = json.load(dsfp)\n",
    "      for o in ds['data']:\n",
    "        if 'answer_start' not in o['answers']:\n",
    "          o['answers']['answer_start'] = list(map(lambda a : o['context'].find(a), o['answers']['text']))\n",
    "  \n",
    "    with open('dataset.json', 'w') as dsfp:\n",
    "      json.dump(ds, dsfp)\n",
    "    \n",
    "  except FileNotFoundError as _:\n",
    "    return\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = get_context_and_answers(questions)\n",
    "# update_answer_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_as_dataset(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-89ba9d214aab74c0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/miteshkumar/.cache/huggingface/datasets/json/default-89ba9d214aab74c0/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 1278.75it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 320.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/miteshkumar/.cache/huggingface/datasets/json/default-89ba9d214aab74c0/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_set = load_dataset('json', data_files={'validation': './dataset.json'}, field=\"data\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('deepset/bert-base-cased-squad2', return_token_type_ids=True)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('deepset/bert-base-cased-squad2')\n",
    "qa_pl = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
    "# from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased',return_token_type_ids = True)\n",
    "# model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_answer_token_ids(model, encoding):\n",
    "#     input_ids, attention_mask = encoding['input_ids'], encoding['attention_mask']\n",
    "#     res = model(torch.tensor([input_ids]),\n",
    "#         attention_mask=torch.tensor([attention_mask]))\n",
    "    \n",
    "#     start_scores = res.start_logits\n",
    "#     end_scores = res.end_logits\n",
    "    \n",
    "#     a_start = torch.argmax(start_scores)\n",
    "#     a_end = torch.argmax(end_scores) + 1\n",
    "#     return input_ids[a_start: a_end]\n",
    "\n",
    "def get_answer_token_ids(question, context):\n",
    "    return tokenizer.encode(qa_pl(question=question, context=context)['answer'])\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is capstone? \n",
      "Answer Tokens: [101, 170, 1902, 1736, 102]\n",
      "Answer: a design course\n"
     ]
    }
   ],
   "source": [
    "# context = \"The US has passed the peak on new coronavirus cases, \" \\\n",
    "#           \"President Donald Trump said and predicted that some states would reopen this month. \" \\\n",
    "#           \"The US has over 637,000 confirmed Covid-19 cases and over 30,826 deaths, the highest for any country in the world.\"\n",
    "\n",
    "# context = context.lower()\n",
    "# question = \"What was President Donald Trump's prediction?\"\n",
    "# question = question.lower()\n",
    "context = \"Capstone is a design course.\"\n",
    "question = \"What is capstone?\"\n",
    "\n",
    "encoding = tokenizer.encode_plus(question, context)\n",
    "answer_token_ids = get_answer_token_ids(question, context)\n",
    "answer_tokens = tokenizer.convert_ids_to_tokens(answer_token_ids, skip_special_tokens=True)\n",
    "print(f'Question: {question} \\nAnswer Tokens: {answer_token_ids}')\n",
    "print(f'Answer: {tokenizer.convert_tokens_to_string(answer_tokens)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:04<00:00,  2.62ex/s]\n"
     ]
    }
   ],
   "source": [
    "def predict_helper(context, question):\n",
    "    return {'predictions': get_answer_token_ids(question, context)}\n",
    "\n",
    "with_predictions = data_set.map(lambda x : predict_helper(x['context'], x['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'predictions'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 2007.32ex/s]\n"
     ]
    }
   ],
   "source": [
    "def get_ans_token_ids(answers):\n",
    "    ans_text = answers['text']\n",
    "    ans_text = ans_text[0]\n",
    "    return tokenizer.encode(ans_text)\n",
    "with_answers = with_predictions.map(lambda x : {'answer_tokens': get_ans_token_ids(x['answers'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'predictions', 'answer_tokens'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 2685.93ex/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 744.57ex/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 1246.91ex/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def f1_accuracy(predicted_tokens, actual_tokens):\n",
    "    predicted_tokens = Counter(predicted_tokens)\n",
    "    actual_tokens = Counter(actual_tokens)\n",
    "    num_shared = sum(min(predicted_tokens[k], actual_tokens[k]) for k in predicted_tokens)\n",
    "    if num_shared == 0:\n",
    "        return {'f1_accuracy': -1}\n",
    "    precision = num_shared/len(predicted_tokens)\n",
    "    recall = num_shared/len(actual_tokens)\n",
    "\n",
    "    return {'f1_accuracy': 2.0 * ((precision * recall)/(precision + recall))}\n",
    "    # return {'f1_accuracy': 2.0/((1.0/precision) + (1.0/recall))}\n",
    "\n",
    "with_f1 = with_answers.map(lambda x : f1_accuracy(x['predictions'], x['answer_tokens']))\n",
    "# with_f1 = with_f1.filter(lambda x : x['f1_accuracy'] >= 0)\n",
    "\n",
    "def token_ids_to_sentence(token_ids):\n",
    "    return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(token_ids, skip_special_tokens=True))\n",
    "\n",
    "with_f1 = with_f1.map(lambda x : {'predicted_sentence': token_ids_to_sentence(x['predictions'])})\n",
    "with_f1 = with_f1.map(lambda x : {'answer_text': x['answers']['text']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_csv = with_f1.to_pandas().to_csv()\n",
    "with open('accuracy_table.csv', 'w') as accuracy_fp:\n",
    "    accuracy_fp.write(accuracy_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9d9c855893fdd03d4f5f1005eb80e345621e0c0e6b19391d93f402c60565b2d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
